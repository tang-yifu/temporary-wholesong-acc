{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract information from midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from mido import MidiFile\n",
    "import mido\n",
    "import random\n",
    "import pretty_midi\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP = True\n",
    "file_name = \"/home/ubuntu/whole-song-gen_acc/external_data/multi_tempo/tempo_change.mid\"# melody as condition\n",
    "file_path = \"/\".join(file_name.split(\"/\")[:-1])# get the path of the folder\n",
    "\n",
    "START_MEASURE = 0\n",
    "END_MEASURE = 8\n",
    "GENERATE_FROM = \"lsh\" # starting from lsh to generate, means skipping frm and ctp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for testing how it works with tempo change\n",
    "pm = pretty_midi.PrettyMIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "extract tempo\n",
    "'''\n",
    "\n",
    "midiFile = mido.MidiFile(file_name, clip=CLIP)\n",
    "events = [e.tempo for e in midiFile.tracks[0] if e.type == \"set_tempo\"]\n",
    "beat_length = mido.tick2second(120, 480, events[0])\n",
    "\n",
    "# print(15.0 / beat_length)\n",
    "with open(\"{}/tempo.txt\".format(file_path), \"w\") as f:\n",
    "\tf.write(str(int(15.0 / beat_length)))\n",
    "\n",
    "TEMPO = int(15.0 / beat_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps saved to /home/ubuntu/whole-song-gen_acc/external_data/multi_tempo/timestamps.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "get_timestamp (not sure what it is)\n",
    "'''\n",
    "\n",
    "try:\n",
    "    midi_data = pretty_midi.PrettyMIDI(file_name, clip=CLIP)\n",
    "except Exception as e:\n",
    "    print(f\"Could not read {file_name}: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Collecting note times in seconds and beats\n",
    "times = []\n",
    "beats = []\n",
    "\n",
    "for instrument in midi_data.instruments:\n",
    "    for note in instrument.notes:\n",
    "        times.append(note.start)  # Note start time in seconds\n",
    "\n",
    "# Convert to beats using the tempo map\n",
    "beats = [midi_data.time_to_tick(time) / midi_data.resolution for time in times]\n",
    "\n",
    "# Pairing the times and beats\n",
    "timestamps = list(zip(times, beats))\n",
    "\n",
    "# Sorting the timestamps based on time in seconds\n",
    "timestamps.sort(key=lambda x: x[0])\n",
    "\n",
    "output_file = os.path.join(file_path, \"timestamps.txt\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for t in timestamps:\n",
    "        f.write(f\"{t[0]} {t[1]}\\n\")\n",
    "\n",
    "print(f\"Timestamps saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT PATH /home/ubuntu/whole-song-gen_acc/external_data/multi_tempo/chord_midi.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['N', 8],\n",
       " ['Bb:maj(9)', 2],\n",
       " ['F:sus2', 2],\n",
       " ['Bb:maj(9)', 2],\n",
       " ['F:sus2', 2],\n",
       " ['Bb:maj(9)', 2],\n",
       " ['F:sus2', 2],\n",
       " ['Bb:maj(9)', 2],\n",
       " ['F:sus2', 2],\n",
       " ['Bb:maj(9)', 2],\n",
       " ['F:maj(9)', 2],\n",
       " ['Bb:maj6(9)', 2],\n",
       " ['G:min7/b7', 2],\n",
       " ['Bb:maj9', 2],\n",
       " ['Bb:min/5', 2],\n",
       " ['Bb:min9', 4],\n",
       " ['C:min9', 6],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj9', 4],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj6(9)', 3],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj(9)', 2],\n",
       " ['F:maj(9)', 2],\n",
       " ['Bb:maj6(9)', 3],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj9', 2],\n",
       " ['Bb:min/5', 2],\n",
       " ['Bb:min9', 3],\n",
       " ['C:9', 7],\n",
       " ['F:13', 2],\n",
       " ['D:min(11)', 4],\n",
       " ['G:11', 2],\n",
       " ['Bb:min6', 1],\n",
       " ['B:hdim7', 1],\n",
       " ['C:min9', 4],\n",
       " ['Eb:hdim7', 1],\n",
       " ['D:dim7', 1],\n",
       " ['C#:dim7', 1],\n",
       " ['C:hdim7', 1],\n",
       " ['Bb:maj', 3],\n",
       " ['F:7', 1],\n",
       " ['Bb:maj', 2],\n",
       " ['Eb:sus4(b7)', 1],\n",
       " ['F:7', 1],\n",
       " ['Bb:min', 2],\n",
       " ['F:sus4(b7,9)', 2],\n",
       " ['F#:maj/3', 2],\n",
       " ['F#:9', 2],\n",
       " ['Bb:min6', 2],\n",
       " ['F:11', 2],\n",
       " ['Bb:min', 2],\n",
       " ['F:maj(11)', 2],\n",
       " ['Ab:minmaj7', 4],\n",
       " ['C#:13', 4],\n",
       " ['F#:maj', 6],\n",
       " ['C#:aug', 2],\n",
       " ['C:hdim7', 5],\n",
       " ['A:maj9', 3],\n",
       " ['D:min7', 4],\n",
       " ['G:7', 4],\n",
       " ['C:min11', 20],\n",
       " ['F:sus4(b7,9)', 12],\n",
       " ['Bb:maj(9)', 7],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj(9)', 2],\n",
       " ['Bb:min/5', 2],\n",
       " ['Bb:min9', 4],\n",
       " ['C:min11', 6],\n",
       " ['F:13', 2],\n",
       " ['D:min7', 2],\n",
       " ['G:7', 3],\n",
       " ['F:maj/3', 1],\n",
       " ['Bb:min6', 1],\n",
       " ['B:dim', 1],\n",
       " ['C:min7', 4],\n",
       " ['F#:maj6', 2],\n",
       " ['F:sus4(b7,9)', 2],\n",
       " ['Bb:maj', 2],\n",
       " ['F:9', 2],\n",
       " ['Bb:maj', 2],\n",
       " ['F:7(#9)', 2],\n",
       " ['Bb:maj9', 2],\n",
       " ['F:maj(9)', 2],\n",
       " ['Bb:maj6(9)', 2],\n",
       " ['G:min7/b7', 2],\n",
       " ['Bb:maj9', 2],\n",
       " ['Bb:min/5', 2],\n",
       " ['Bb:min9', 4],\n",
       " ['C:min9', 6],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj9', 4],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj6(9)', 3],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj(9)', 2],\n",
       " ['F:maj(9)', 2],\n",
       " ['Bb:maj6(9)', 3],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj9', 2],\n",
       " ['Bb:min/5', 2],\n",
       " ['Bb:min9', 3],\n",
       " ['C:9', 7],\n",
       " ['F:13', 2],\n",
       " ['D:min(11)', 4],\n",
       " ['G:11', 2],\n",
       " ['Bb:min6', 1],\n",
       " ['B:hdim7', 1],\n",
       " ['C:min9', 4],\n",
       " ['Eb:hdim7', 1],\n",
       " ['D:dim7', 1],\n",
       " ['C#:dim7', 1],\n",
       " ['C:hdim7', 1],\n",
       " ['Bb:maj', 3],\n",
       " ['F:7', 1],\n",
       " ['Bb:maj', 2],\n",
       " ['Eb:sus4(b7)', 1],\n",
       " ['F:7', 1],\n",
       " ['Bb:min', 2],\n",
       " ['F:sus4(b7,9)', 2],\n",
       " ['F#:maj/3', 2],\n",
       " ['F#:9', 2],\n",
       " ['Bb:min6', 2],\n",
       " ['F:11', 2],\n",
       " ['Bb:min', 2],\n",
       " ['F:maj(11)', 2],\n",
       " ['Ab:minmaj7', 4],\n",
       " ['C#:13', 4],\n",
       " ['F#:maj', 6],\n",
       " ['C#:aug', 2],\n",
       " ['C:hdim7', 5],\n",
       " ['A:maj9', 3],\n",
       " ['D:min7', 4],\n",
       " ['G:7', 4],\n",
       " ['C:min11', 20],\n",
       " ['F:sus4(b7,9)', 12],\n",
       " ['Bb:maj(9)', 7],\n",
       " ['F:aug', 1],\n",
       " ['Bb:maj(9)', 2],\n",
       " ['Bb:min/5', 2],\n",
       " ['Bb:min9', 4],\n",
       " ['C:min11', 6],\n",
       " ['F:13', 2],\n",
       " ['D:min7', 2],\n",
       " ['G:7', 3],\n",
       " ['F:maj/3', 1],\n",
       " ['Bb:min6', 1],\n",
       " ['B:dim', 1],\n",
       " ['C:min9', 4],\n",
       " ['F:11', 4],\n",
       " ['Bb:maj', 2],\n",
       " ['F:aug', 2],\n",
       " ['Bb:maj6(9)', 2],\n",
       " ['F:min11', 2],\n",
       " ['Bb:maj6(9)', 8]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "chord recognition\n",
    "'''\n",
    "sys.path.append(\"preprocessing\")\n",
    "sys.path.append(\"preprocessing/exported_midi_chord_recognition\")\n",
    "from preprocessing.exported_midi_chord_recognition.main import transcribe_cb1000_midi\n",
    "from preprocessing.finalize_chord_midi_only import finalize\n",
    "\n",
    "output_path = \"{}/chord_midi.txt\".format(\n",
    "    \"/\".join(file_name.split(\"/\")[:-1]))\n",
    "print(\"OUTPUT PATH\", output_path)\n",
    "transcribe_cb1000_midi(file_name,output_path,clip=CLIP)\n",
    "#print(\"aaa\")\n",
    "finalize(file_name, save_file=True, save_summary=True, clip=CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "melody extract\n",
    "'''\n",
    "\n",
    "from preprocessing.melody_extract_test import save_melody\n",
    "save_melody(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "key finding\n",
    "'''\n",
    "# note that key finding is based on chords\n",
    "\n",
    "from preprocessing.key_finding import calculate_key_sig, calculate_time_sig\n",
    "KEY = calculate_key_sig(file_name)\n",
    "TIME_SIG = calculate_time_sig(file_name, clip=CLIP)\n",
    "NUM_BEAT_PER_MEASURE = TIME_SIG[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melody reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"melody_reduction\")\n",
    "from melody_reduction.utils import read_data, output_to_midi, DEMO_FOLDER\n",
    "from melody_reduction.run_melody_reduction import run_melody_reduction_of_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/whole-song-gen_acc/external_data/multi_tempo/tempo_change-red.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.68s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset2 = [read_data(data_fn=file_path, num_beat_per_measure=NUM_BEAT_PER_MEASURE, \n",
    "                      num_step_per_beat=4, song_name=file_name.split(\"/\")[-1].split(\".\")[0], label=1)]\n",
    "\n",
    "# os.makedirs(\"synthwave\", exist_ok=True)\n",
    "num_path = 1\n",
    "bpm = TEMPO\n",
    "plot_graph = False\n",
    "\n",
    "# dataset: a list of dictionary containing keys: 'song_name', 'melody', 'chord', 'phrase_label',\n",
    "# 'num_beat_per_measure' and 'num_step_per_beat'.\n",
    "run_melody_reduction_of_dataset(dataset2, file_path, num_path, plot_graph, bpm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "from data_utils.pytorch_datasets.base_class import *\n",
    "# import data_utils\n",
    "# importlib.reload(data_utils)\n",
    "from data_utils.utils.read_file import read_data_no_acc\n",
    "from data_utils.read_pop909_data import analyze_pop909_dataset_without_acc\n",
    "from data_utils.pytorch_datasets import create_form_datasets, create_counterpoint_datasets, create_leadsheet_datasets, \\\n",
    "    create_accompaniment_datasets\n",
    "from data_utils.utils.song_analyzer import LanguageExtractor\n",
    "from data_utils.pytorch_datasets.const import LANGUAGE_DATASET_PARAMS, AUTOREG_PARAMS, SHIFT_HIGH_T, SHIFT_LOW_T, SHIFT_HIGH_V, SHIFT_LOW_V\n",
    "from data_utils.pytorch_datasets.form_dataset import FormDataset\n",
    "from data_utils.pytorch_datasets.counterpoint_dataset import CounterpointDataset\n",
    "from data_utils.pytorch_datasets.leadsheet_dataset import LeadSheetDataset\n",
    "\n",
    "\n",
    "class ExtractFormCounterpointLeadsheet:\n",
    "    def __init__(self, analyses):\n",
    "        self.n_channels_frm = 8\n",
    "        self.n_channels_ctp = 10\n",
    "        self.n_channels_lsh = 12\n",
    "        self.h_frm = 16\n",
    "        self.h_ctp = 128\n",
    "        self.h_lsh = 128\n",
    "\n",
    "        self.frm_max_l = [analysis['languages']['form']['key_roll'].shape[1] for analysis in analyses]\n",
    "        self.ctp_max_l = [analysis['languages']['counterpoint']['red_mel_roll'].shape[1] for analysis in analyses]\n",
    "        self.lsh_max_l = [analysis['languages']['lead_sheet']['mel_roll'].shape[1] for analysis in analyses]\n",
    "\n",
    "        form_langs = [analysis['languages']['form'] for analysis in analyses]\n",
    "        ctpt_langs = [analysis['languages']['counterpoint'] for analysis in analyses]\n",
    "        ldsht_langs = [analysis['languages']['lead_sheet'] for analysis in analyses]\n",
    "\n",
    "        self.min_mel_pitches = [analysis['min_mel_pitch'] for analysis in analyses]\n",
    "        self.max_mel_pitches = [analysis['max_mel_pitch'] for analysis in analyses]\n",
    "\n",
    "        self.nbpms = [analysis['nbpm'] for analysis in analyses]\n",
    "        self.nspbs = [analysis['nspb'] for analysis in analyses]\n",
    "        self.song_names = [analysis['name'] for analysis in analyses]\n",
    "\n",
    "        self.key_rolls = [form_lang['key_roll'] for form_lang in form_langs]\n",
    "        self.key_rolls_ctp = [expand_roll(roll, nbpm) for roll, nbpm in zip(self.key_rolls, self.nbpms)]\n",
    "        self.key_rolls_lsh = [expand_roll(roll, nbpm * nspb)\n",
    "                          for roll, nbpm, nspb in zip(self.key_rolls, self.nbpms, self.nspbs)]\n",
    "\n",
    "        self.phrase_rolls = [form_lang['phrase_roll'][:, :, np.newaxis] for form_lang in form_langs]\n",
    "        self.phrase_rolls_ctp = [expand_roll(roll, nbpm) for roll, nbpm in zip(self.phrase_rolls, self.nbpms)]\n",
    "        self.phrase_rolls_lsh = [expand_roll(roll, nbpm * nspb)\n",
    "                             for roll, nbpm, nspb in zip(self.phrase_rolls, self.nbpms, self.nspbs)]\n",
    "\n",
    "        self.red_mel_rolls = [ctpt_lang['red_mel_roll'] for ctpt_lang in ctpt_langs]\n",
    "        self.red_mel_rolls_lsh = [expand_roll(roll, nspb, contain_onset=True)\n",
    "                              for roll, nspb in zip(self.red_mel_rolls, self.nspbs)]\n",
    "        \n",
    "        self.red_chd_rolls = [ctpt_lang['red_chd_roll'] for ctpt_lang in ctpt_langs]\n",
    "        self.red_chd_rolls_lsh = [expand_roll(roll, nspb, contain_onset=True)\n",
    "                              for roll, nspb in zip(self.red_chd_rolls, self.nspbs)]\n",
    "\n",
    "        self.mel_rolls = [ldsht_lang['mel_roll'] for ldsht_lang in ldsht_langs]\n",
    "        self.chd_rolls = [ldsht_lang['chd_roll'] for ldsht_lang in ldsht_langs]\n",
    "        self.chd_rolls_lsh = [expand_roll(roll, nspb, contain_onset=True)\n",
    "                          for roll, nspb in zip(self.chd_rolls, self.nspbs)]\n",
    "\n",
    "\n",
    "    def get_data_sample_frm(self, song_id=0, start_id=0, end_id=None):\n",
    "\n",
    "        # store_key\n",
    "        if self.key_rolls is not None:\n",
    "            key_roll = self.key_rolls[song_id]\n",
    "            self._key = np.roll(key_roll, shift=0, axis=-1)\n",
    "        \n",
    "        # store_phrase\n",
    "        if self.phrase_rolls is not None:\n",
    "            self._phrase = self.phrase_rolls[song_id]\n",
    "\n",
    "        if end_id is None:\n",
    "            end_id = self.frm_max_l[song_id]\n",
    "\n",
    "        img = self.lang_to_img_frm(start_id, end_id=end_id, tgt_lgth=end_id-start_id)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def get_data_sample_ctp(self, song_id=0, start_id=0, end_id=None):\n",
    "        nbpm = self.nbpms[song_id]\n",
    "\n",
    "        # store_key\n",
    "        if self.key_rolls_ctp is not None:\n",
    "            key_roll = self.key_rolls_ctp[song_id]\n",
    "            self._key = np.roll(key_roll, shift=0, axis=-1)\n",
    "        \n",
    "        # store_phrase\n",
    "        if self.phrase_rolls_ctp is not None:\n",
    "            self._phrase = self.phrase_rolls_ctp[song_id]\n",
    "\n",
    "        # store_red_mel\n",
    "        if self.red_mel_rolls is not None:\n",
    "            red_mel_roll = self.red_mel_rolls[song_id]\n",
    "            self._red_mel = np.roll(red_mel_roll, shift=0, axis=-1)\n",
    "\n",
    "        # store_red_chd\n",
    "        if self.red_chd_rolls is not None:\n",
    "            red_chd_roll = self.red_chd_rolls[song_id]\n",
    "            self._red_chd = np.roll(red_chd_roll, shift=0, axis=-1)\n",
    "\n",
    "        if end_id is None:\n",
    "            end_id = self.ctp_max_l[song_id]\n",
    "        img = self.lang_to_img_ctp(start_id, end_id, tgt_lgth=end_id-start_id)\n",
    "        return img\n",
    "        \n",
    "    def get_data_sample_lsh(self, song_id=0, start_id=0, end_id=None):\n",
    "        nbpm, nspb = self.nbpms[song_id], self.nspbs[song_id]\n",
    "\n",
    "        # self.store_key(song_id, pitch_shift)\n",
    "        if self.key_rolls_lsh is not None:\n",
    "            key_roll = self.key_rolls_lsh[song_id]\n",
    "            self._key = np.roll(key_roll, shift=0, axis=-1)\n",
    "\n",
    "        # self.store_phrase(song_id)\n",
    "        if self.phrase_rolls_lsh is not None:\n",
    "            self._phrase = self.phrase_rolls_lsh[song_id]\n",
    "\n",
    "        # self.store_red_mel(song_id, pitch_shift)\n",
    "        if self.red_mel_rolls_lsh is not None:\n",
    "            red_mel_roll = self.red_mel_rolls_lsh[song_id]\n",
    "            self._red_mel = np.roll(red_mel_roll, shift=0, axis=-1)\n",
    "\n",
    "        # self.store_red_chd(song_id, pitch_shift)\n",
    "        if self.red_chd_rolls_lsh is not None:\n",
    "            red_chd_roll = self.red_chd_rolls_lsh[song_id]\n",
    "            self._red_chd = np.roll(red_chd_roll, shift=0, axis=-1)\n",
    "\n",
    "        # self.store_mel(song_id, pitch_shift)\n",
    "        if self.mel_rolls is not None:\n",
    "            mel_roll = self.mel_rolls[song_id]\n",
    "            self._mel = np.roll(mel_roll, shift=0, axis=-1)\n",
    "\n",
    "        # self.store_chd(song_id, pitch_shift)\n",
    "        if self.chd_rolls_lsh is not None:\n",
    "            chd_roll = self.chd_rolls_lsh[song_id]\n",
    "            self._chd = np.roll(chd_roll, shift=0, axis=-1)\n",
    "\n",
    "        if end_id is None:\n",
    "            end_id = self.lsh_max_l[song_id]\n",
    "\n",
    "        img = self.lang_to_img_lsh(start_id, end_id=end_id, tgt_lgth=end_id-start_id)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def lang_to_img_frm(self, start_id, end_id, tgt_lgth=None):\n",
    "        key_roll = self._key[:, start_id: end_id]  # (2, L, 12)\n",
    "        phrase_roll = self._phrase[:, start_id: end_id]  # (6, L, 1)\n",
    "\n",
    "        # actual_l = self._key.shape[1]\n",
    "\n",
    "        # to output image\n",
    "        if tgt_lgth is None:\n",
    "            tgt_lgth = end_id - start_id\n",
    "        img = np.zeros((self.n_channels_frm, tgt_lgth, self.h_frm), dtype=np.float32)\n",
    "        img[0: 2, 0: tgt_lgth, 0: 12] = key_roll\n",
    "        img[2: 8, 0: tgt_lgth] = phrase_roll\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def lang_to_img_ctp(self, start_id, end_id, tgt_lgth=None):\n",
    "        print(tgt_lgth)\n",
    "        key_roll = self._key[:, start_id: end_id]  # (2, L, 12)\n",
    "        phrase_roll = self._phrase[:, start_id: end_id]  # (6, L, 1)\n",
    "        red_mel_roll = self._red_mel[:, start_id: end_id]  # (2, L, 128)\n",
    "        red_chd_roll = self._red_chd[:, start_id: end_id]  # (6, L, 12)\n",
    "\n",
    "        # actual_l = key_roll.shape[1]\n",
    "\n",
    "        # to output image\n",
    "        if tgt_lgth is None:\n",
    "            tgt_lgth = self._key.shape[1] - start_id\n",
    "        img = np.zeros((self.n_channels_ctp, tgt_lgth, 132), dtype=np.float32)\n",
    "        print(tgt_lgth, red_mel_roll.shape)\n",
    "        img[0: 2, 0: tgt_lgth, 0: 128] = red_mel_roll\n",
    "        img[0: 2, 0: tgt_lgth, 36: 48] = red_chd_roll[2: 4]\n",
    "        img[0: 2, 0: tgt_lgth, 24: 36] = red_chd_roll[4: 6]\n",
    "\n",
    "        img[4: 10, 0: tgt_lgth] = phrase_roll\n",
    "\n",
    "        img = img.reshape((self.n_channels_ctp, tgt_lgth, 11, 12))\n",
    "        img[2: 4, 0: tgt_lgth] = key_roll[:, :, np.newaxis]\n",
    "        img = img.reshape((self.n_channels_ctp, tgt_lgth, 132))\n",
    "        return img[:, :, 0: self.h_ctp]\n",
    "    \n",
    "    def lang_to_img_lsh(self, start_id, end_id, tgt_lgth=None):\n",
    "        key_roll = self._key[:, start_id: end_id]  # (2, L, 12)\n",
    "        phrase_roll = self._phrase[:, start_id: end_id]  # (6, L, 1)\n",
    "        red_mel_roll = self._red_mel[:, start_id: end_id]  # (2, L, 128)\n",
    "        red_chd_roll = self._red_chd[:, start_id: end_id]  # (6, L, 12)\n",
    "        mel_roll = self._mel[:, start_id: end_id]\n",
    "        chd_roll = self._chd[:, start_id: end_id]\n",
    "\n",
    "        # actual_l = key_roll.shape[1]\n",
    "\n",
    "        # to output image\n",
    "        if tgt_lgth is None:\n",
    "            tgt_lgth = end_id - start_id\n",
    "        img = np.zeros((self.n_channels_lsh, tgt_lgth, 132), dtype=np.float32)\n",
    "        img[0: 2, 0: tgt_lgth, 0: 128] = mel_roll\n",
    "        img[0: 2, 0: tgt_lgth, 36: 48] = chd_roll[2: 4]\n",
    "        img[0: 2, 0: tgt_lgth, 24: 36] = chd_roll[4: 6]\n",
    "\n",
    "        img[2: 4, 0: tgt_lgth, 0: 128] = red_mel_roll\n",
    "        img[2: 4, 0: tgt_lgth, 36: 48] = red_chd_roll[2: 4]\n",
    "        img[2: 4, 0: tgt_lgth, 24: 36] = red_chd_roll[4: 6]\n",
    "\n",
    "        img[6: 12, 0: tgt_lgth] = phrase_roll\n",
    "\n",
    "        img = img.reshape((self.n_channels_lsh, tgt_lgth, 11, 12))\n",
    "        img[4: 6, 0: tgt_lgth] = key_roll[:, :, np.newaxis]\n",
    "        img = img.reshape((self.n_channels_lsh, tgt_lgth, 132))\n",
    "        return img[:, :, 0: self.h_lsh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = read_data_no_acc(file_path, num_beat_per_measure=NUM_BEAT_PER_MEASURE, num_step_per_beat=4,\n",
    "              clean_chord_unit=None, song_name=None, label=1)\n",
    "lang_extractor = LanguageExtractor(song_data)\n",
    "hie_lang = lang_extractor.analyze_without_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 111, 12)\n",
      "(2, 444, 128)\n",
      "(2, 1776, 128)\n"
     ]
    }
   ],
   "source": [
    "print(hie_lang['languages']['form']['key_roll'].shape)\n",
    "print(hie_lang['languages']['counterpoint']['red_mel_roll'].shape)\n",
    "print(hie_lang['languages']['lead_sheet']['mel_roll'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32 (2, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "mega_data = ExtractFormCounterpointLeadsheet([hie_lang])\n",
    "\n",
    "frm = mega_data.get_data_sample_frm(start_id=START_MEASURE, end_id=END_MEASURE)\n",
    "ctp = mega_data.get_data_sample_ctp(start_id=START_MEASURE, end_id=END_MEASURE*NUM_BEAT_PER_MEASURE)\n",
    "lsh = mega_data.get_data_sample_lsh(start_id=START_MEASURE, end_id=END_MEASURE*NUM_BEAT_PER_MEASURE*4)\n",
    "\n",
    "frm = np.expand_dims(frm, axis=0)\n",
    "ctp = np.expand_dims(ctp, axis=0)\n",
    "lsh = np.expand_dims(lsh, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default default default default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of the experiment is: m0-v-default-default\n",
      "m1-v-default-default\n",
      "m2-v-default-default\n",
      "m3-v-default-default\n"
     ]
    }
   ],
   "source": [
    "# whole_song_gen_notebook.ipynb\n",
    "\n",
    "# Import necessary libraries\n",
    "from experiments.whole_song_gen import WholeSongGeneration\n",
    "import torch\n",
    "\n",
    "# Default model folders and demo directory\n",
    "DEFAULT_FRM_MODEL_FOLDER = 'results_default/frm---/v-default'\n",
    "DEFAULT_CTP_MODEL_FOLDER = 'results_default/ctp-a-b-/v-default'\n",
    "DEFAULT_LSH_MODEL_FOLDER = 'results_default/lsh-a-b-/v-default'\n",
    "DEFAULT_ACC_MODEL_FOLDER = 'results_default/acc-a-b-/v-default'\n",
    "DEFAULT_DEMO_DIR = 'demo'\n",
    "\n",
    "# Set the argument values directly\n",
    "args = {\n",
    "    'mpath0': DEFAULT_FRM_MODEL_FOLDER,\n",
    "    'mid0': 'default',\n",
    "    'mpath1': DEFAULT_CTP_MODEL_FOLDER,\n",
    "    'mid1': 'default',\n",
    "    'mpath2': DEFAULT_LSH_MODEL_FOLDER,\n",
    "    'mid2': 'default',\n",
    "    'mpath3': DEFAULT_ACC_MODEL_FOLDER,\n",
    "    'mid3': 'default',\n",
    "    'nsample': 1,\n",
    "    'debug': False\n",
    "}\n",
    "\n",
    "# Check available device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Initialize the whole song generation pipeline\n",
    "whole_song_expr = WholeSongGeneration.init_pipeline(\n",
    "    frm_model_folder=args['mpath0'],\n",
    "    ctp_model_folder=args['mpath1'],\n",
    "    lsh_model_folder=args['mpath2'],\n",
    "    acc_model_folder=args['mpath3'],\n",
    "    frm_model_id=args['mid0'],\n",
    "    ctp_model_id=args['mid1'],\n",
    "    lsh_model_id=args['mid2'],\n",
    "    acc_model_id=args['mid3'],\n",
    "    debug_mode=args['debug'],\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from inference.utils import quantize_generated_form_batch, specify_form\n",
    "\n",
    "n_sample=args['nsample']\n",
    "nbpm=NUM_BEAT_PER_MEASURE\n",
    "nspb=4  # assuming nspb is a constant value\n",
    "phrase_string=dataset2[0][\"phrase_label\"][0][\"name\"]\n",
    "key_to_number = {\n",
    "    'C': 0,\n",
    "    'C#': 1,\n",
    "    'D': 2,\n",
    "    'D#': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'F#': 6,\n",
    "    'G': 7,\n",
    "    'G#': 8,\n",
    "    'A': 9,\n",
    "    'A#': 10,\n",
    "    'Bb': 10,\n",
    "    'B': 11\n",
    "}\n",
    "key=key_to_number[KEY.split(\":\")[0]]\n",
    "is_major=True if KEY.split(\":\")[1] == \"maj\" else False\n",
    "bpm = 110\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accompaniment generation...\n",
      "Number of iterations: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">Sample...</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Accompaniment generation\n",
    "print(\"Accompaniment generation...\")\n",
    "acc_canvas, slices, gen_max_l = \\\n",
    "    whole_song_expr.acc_op.create_canvas(lsh, n_sample, nbpm, nspb, None, whole_song_expr.random_n_autoreg)\n",
    "print(f\"Number of iterations: {len(slices)}\")\n",
    "acc = whole_song_expr.acc_op.generation(acc_canvas, slices, gen_max_l)\n",
    "\n",
    "\n",
    "midi_file = whole_song_expr.output(acc, phrase_string, key, is_major, file_path, bpm, music_name=file_name.split(\"/\")[-1].split(\".\")[0], gen_from=GENERATE_FROM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
